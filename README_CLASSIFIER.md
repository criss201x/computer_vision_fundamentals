# Clasificador de ImÃ¡genes con Autoencoder CNN - VersiÃ³n Mejorada

Sistema completo de clasificaciÃ³n de imÃ¡genes usando un autoencoder convolucional pre-entrenado seguido de un clasificador. Listo para entrenar, evaluar y clasificar imÃ¡genes nuevas en producciÃ³n.

## CaracterÃ­sticas

âœ… **Arquitectura robusta**: Autoencoder CNN con Batch Normalization
âœ… **Entrenamiento optimizado**: Early stopping, learning rate scheduler, validaciÃ³n
âœ… **Data augmentation**: Mejor generalizaciÃ³n con transformaciones aleatorias
âœ… **Sistema de inferencia completo**: Script CLI + notebook para clasificar imÃ¡genes nuevas
âœ… **Guardado robusto**: Metadatos completos, transformaciones, historial de entrenamiento
âœ… **Bugs corregidos**: Flujo dimensional correcto del encoder al clasificador

---

## Estructura del Proyecto

```
computer_vision/
â”œâ”€â”€ autoencoder_cnn_v4_improved.ipynb  # Notebook de entrenamiento mejorado
â”œâ”€â”€ inference.py                        # Script CLI para inferencia
â”œâ”€â”€ inference_notebook.ipynb            # Notebook de inferencia
â”œâ”€â”€ README_CLASSIFIER.md                # Este archivo
â”œâ”€â”€ objetos_salon/processed/            # Dataset de entrenamiento
â”‚   â”œâ”€â”€ mesa/
â”‚   â”œâ”€â”€ mouse/
â”‚   â”œâ”€â”€ nada/
â”‚   â”œâ”€â”€ teclado/
â”‚   â”œâ”€â”€ pantalla/
â”‚   â”œâ”€â”€ cpu/
â”‚   â””â”€â”€ silla/
â””â”€â”€ export_v4/                          # Modelos entrenados (se crea al entrenar)
    â”œâ”€â”€ autoencoder_state.pt
    â”œâ”€â”€ classifier_state.pt
    â”œâ”€â”€ complete_models.pt
    â”œâ”€â”€ metadata.json
    â””â”€â”€ training_history.json
```

---

## InstalaciÃ³n

### Requisitos

```bash
pip install torch torchvision
pip install numpy matplotlib seaborn
pip install scikit-learn pillow
pip install pandas  # opcional, para exportar a CSV
```

---

## Uso

### 1ï¸âƒ£ Entrenamiento (Primera vez)

Abre el notebook [autoencoder_cnn_v4_improved.ipynb](autoencoder_cnn_v4_improved.ipynb) y ejecuta todas las celdas. Esto:

1. CargarÃ¡ tu dataset desde `objetos_salon/processed/`
2. EntrenarÃ¡ el autoencoder
3. EntrenarÃ¡ el clasificador
4. EvaluarÃ¡ el modelo
5. GuardarÃ¡ todo en `export_v4/`

**Tiempo estimado**: 10-30 minutos (dependiendo de tu hardware)

#### ConfiguraciÃ³n personalizada

En el notebook, puedes ajustar los hiperparÃ¡metros en la secciÃ³n de `CONFIG`:

```python
CONFIG = {
    'data_dir': 'objetos_salon/processed',
    'batch_size': 64,
    'latent_dim': 128,
    'ae_epochs': 30,
    'classifier_epochs': 25,
    'img_size': 32,
    # ... mÃ¡s opciones
}
```

---

### 2ï¸âƒ£ Clasificar ImÃ¡genes Nuevas

Una vez entrenado el modelo, tienes **dos opciones** para clasificar imÃ¡genes nuevas:

#### OpciÃ³n A: Script de lÃ­nea de comandos

```bash
# Hacer el script ejecutable (solo una vez)
chmod +x inference.py

# Clasificar una imagen
python inference.py --image mi_imagen.jpg

# Clasificar mÃºltiples imÃ¡genes
python inference.py --image img1.jpg --image img2.jpg --image img3.jpg

# Clasificar todas las imÃ¡genes en una carpeta
python inference.py --folder imagenes_nuevas/

# Ver top-5 predicciones
python inference.py --image img.jpg --top-k 5

# Guardar resultados en JSON
python inference.py --folder imagenes/ --output resultados.json

# Usar modelo de otro directorio
python inference.py --image img.jpg --model-dir export_v3/
```

#### OpciÃ³n B: Notebook interactivo

Abre [inference_notebook.ipynb](inference_notebook.ipynb) y sigue las instrucciones. Es ideal para:
- Visualizar las predicciones
- Experimentar interactivamente
- Exportar resultados a CSV
- AnÃ¡lisis exploratorio

---

## Ejemplos de Uso

### Ejemplo 1: Clasificar una imagen con Python

```python
from inference import ImageClassifierPredictor

# Cargar modelo
predictor = ImageClassifierPredictor(model_dir='export_v4')

# Predecir
predictions = predictor.predict('nueva_imagen.jpg', top_k=3)

# Ver resultados
for i, pred in enumerate(predictions, 1):
    print(f"{i}. {pred['class']}: {pred['confidence_pct']:.2f}%")
```

### Ejemplo 2: Procesar carpeta completa

```python
from inference import ImageClassifierPredictor

predictor = ImageClassifierPredictor(model_dir='export_v4')
results = predictor.predict_folder('carpeta_imagenes/', top_k=1)

# Resumen
for img_path, result in results.items():
    if result['success']:
        pred = result['predictions'][0]
        print(f"{img_path}: {pred['class']} ({pred['confidence_pct']:.1f}%)")
```

### Ejemplo 3: ClasificaciÃ³n con umbral de confianza

```python
predictions = predictor.predict('imagen_dudosa.jpg', top_k=1)
confidence = predictions[0]['confidence_pct']

if confidence >= 80:
    print(f"âœ“ Alta confianza: {predictions[0]['class']}")
elif confidence >= 50:
    print(f"âš  Confianza media: {predictions[0]['class']}")
else:
    print(f"âŒ Confianza baja, revisar manualmente")
```

---

## Arquitectura del Modelo

### Autoencoder

```
Encoder:
  3x32x32 â†’ Conv(16) â†’ MaxPool â†’ 16x16x16
         â†’ Conv(32) â†’ MaxPool â†’ 32x8x8
         â†’ Conv(64) â†’ MaxPool â†’ 64x4x4
         â†’ Flatten â†’ Linear(128) â†’ Latent Code

Decoder:
  Latent Code â†’ Linear(1024) â†’ Reshape(64x4x4)
              â†’ ConvTranspose â†’ 32x8x8
              â†’ ConvTranspose â†’ 16x16x16
              â†’ ConvTranspose â†’ 3x32x32
```

### Clasificador

```
Latent Code (128) â†’ Linear(256) â†’ ReLU â†’ Dropout(0.5)
                  â†’ Linear(128) â†’ ReLU â†’ Dropout(0.5)
                  â†’ Linear(num_classes)
```

**ParÃ¡metros totales**: ~500K (autoencoder) + ~50K (clasificador)

---

## Mejoras Implementadas vs v3

| CaracterÃ­stica | v3 (Original) | v4 (Mejorada) |
|---|---|---|
| Bug dimensional | âŒ Incorrecto | âœ… Corregido |
| Data augmentation | âŒ No | âœ… SÃ­ |
| ValidaciÃ³n | âŒ Solo train/test | âœ… Train/val/test |
| Early stopping | âŒ No | âœ… SÃ­ |
| Batch normalization | âŒ No | âœ… SÃ­ |
| LR scheduler | âŒ No | âœ… SÃ­ |
| Metadatos | âš ï¸ Incompletos | âœ… Completos |
| Inferencia | âŒ No disponible | âœ… CLI + Notebook |
| Transformaciones guardadas | âŒ No | âœ… SÃ­ |
| Visualizaciones | âš ï¸ BÃ¡sicas | âœ… Completas |

---

## Flujo de Trabajo Recomendado

### Para agregar nuevas imÃ¡genes en el futuro:

1. **OpciÃ³n A: Re-entrenar con datos nuevos**
   ```bash
   # 1. Agregar imÃ¡genes al dataset
   # objetos_salon/processed/nueva_clase/*.jpg

   # 2. Ejecutar notebook de entrenamiento
   # Esto crearÃ¡ un nuevo modelo en export_v4/
   ```

2. **OpciÃ³n B: Usar modelo actual (solo inferencia)**
   ```bash
   # Si las nuevas imÃ¡genes son de clases ya conocidas
   python inference.py --folder nuevas_imagenes/
   ```

### Para agregar una nueva clase:

1. Crear carpeta para la nueva clase:
   ```bash
   mkdir objetos_salon/processed/nueva_clase
   # Agregar imÃ¡genes de entrenamiento
   ```

2. Re-entrenar el modelo completo usando el notebook

3. El nuevo modelo clasificarÃ¡ todas las clases (antiguas + nueva)

---

## ResoluciÃ³n de Problemas

### Error: "No se encontrÃ³ metadata.json"

**Causa**: El modelo no ha sido entrenado todavÃ­a.
**SoluciÃ³n**: Ejecuta el notebook de entrenamiento primero.

### Error: "CUDA out of memory"

**Causa**: GPU sin suficiente memoria.
**SoluciÃ³n**: Reduce `batch_size` en CONFIG o usa CPU:
```python
predictor = ImageClassifierPredictor(device='cpu')
```

### Predicciones con confianza muy baja

**Causa**: La imagen es muy diferente al dataset de entrenamiento.
**SoluciÃ³n**:
1. Verifica que la imagen sea de una clase conocida
2. Agrega mÃ¡s datos de entrenamiento similares
3. Re-entrena el modelo

### Las imÃ¡genes no se clasifican correctamente

**Posibles causas**:
1. **Imagen muy diferente al training set**: Agregar mÃ¡s datos similares
2. **Clase desbalanceada**: Verificar que cada clase tenga suficientes imÃ¡genes
3. **Overfitting**: Usar mÃ¡s data augmentation o aumentar dropout

---

## PersonalizaciÃ³n Avanzada

### Cambiar el tamaÃ±o de las imÃ¡genes

```python
CONFIG = {
    'img_size': 64,  # Cambiar de 32 a 64
    # ... otros parÃ¡metros
}
```

**Nota**: DeberÃ¡s ajustar la arquitectura del autoencoder si cambias el tamaÃ±o.

### Descongelar el encoder para fine-tuning

En el notebook, modifica:

```python
classifier = ImprovedClassifier(
    autoencoder=autoencoder,
    num_classes=num_classes,
    dropout=CONFIG['dropout'],
    freeze_encoder=False  # Cambiar a False
)
```

### Exportar a ONNX para producciÃ³n

```python
import torch.onnx

dummy_input = torch.randn(1, 3, 32, 32).to(device)
torch.onnx.export(
    classifier,
    dummy_input,
    "model.onnx",
    input_names=['input'],
    output_names=['output']
)
```

---

## MÃ©tricas de Rendimiento

El modelo reporta:
- **Accuracy** en train/val/test
- **Precision, Recall, F1-score** por clase
- **Matriz de confusiÃ³n**
- **Curvas de aprendizaje** (loss y accuracy)

Ejemplo de output:

```
Test Accuracy: 92.34%

Classification Report:
              precision    recall  f1-score   support
        cpu       0.91      0.89      0.90        45
       mesa       0.94      0.93      0.94        52
      mouse       0.88      0.91      0.89        38
       nada       0.96      0.97      0.97        61
   pantalla       0.92      0.90      0.91        48
      silla       0.93      0.95      0.94        43
    teclado       0.90      0.88      0.89        50
```

---

## Licencia y CrÃ©ditos

Proyecto creado con PyTorch. Para uso educativo y de investigaciÃ³n.

---

## FAQ

**P: Â¿Puedo usar este modelo para otras tareas?**
R: SÃ­, solo necesitas cambiar el dataset en `CONFIG['data_dir']` y re-entrenar.

**P: Â¿CuÃ¡ntas imÃ¡genes necesito por clase?**
R: MÃ­nimo 50-100 por clase para buenos resultados. MÃ¡s es mejor.

**P: Â¿Puedo usar el autoencoder para otras tareas?**
R: SÃ­, el autoencoder aprende representaciones genÃ©ricas que puedes usar para clustering, detecciÃ³n de anomalÃ­as, etc.

**P: Â¿CÃ³mo sÃ© si mi modelo estÃ¡ en overfitting?**
R: Si train_acc >> val_acc (ej: 95% vs 70%), hay overfitting. Aumenta data augmentation o regularizaciÃ³n.

**P: Â¿Puedo usar el modelo sin GPU?**
R: SÃ­, funcionarÃ¡ en CPU pero serÃ¡ mÃ¡s lento. Para inferencia es aceptable.

---

## PrÃ³ximos Pasos

1. âœ… **Ya tienes**: Sistema completo de entrenamiento e inferencia
2. ğŸ“Š **Recomendado**: Agregar mÃ¡s datos de entrenamiento si accuracy < 90%
3. ğŸš€ **Avanzado**: Implementar API REST con Flask/FastAPI
4. ğŸ“± **ProducciÃ³n**: Exportar a ONNX o TorchScript para deployment

---

## Soporte

Si encuentras problemas:
1. Revisa la secciÃ³n "ResoluciÃ³n de Problemas"
2. Verifica que todos los archivos estÃ©n en su lugar
3. Confirma que el modelo fue entrenado correctamente (existe `export_v4/`)

**Â¡Listo para clasificar! ğŸš€**
