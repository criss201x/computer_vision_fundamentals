{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e7bba3-ad56-4259-9fba-b5e7f2e2ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch, torch.nn as nn, torch.nn.functional as F, math, numpy as np\n",
    "import glob, os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0025260-b160-40df-af7a-b61103cc1422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "CUDA (torch): 12.8\n",
      "GPU name: NVIDIA GeForce RTX 3050 OEM\n",
      "GPU memoria asignada (bytes): 4194304\n"
     ]
    }
   ],
   "source": [
    "#print(torch.__version__)\n",
    "#print('cuda available:', torch.cuda.is_available()) \n",
    "#print('cuda version:', torch.version.cuda)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "if device.type == 'cuda':\n",
    "    try:\n",
    "        print('CUDA (torch):', torch.version.cuda)\n",
    "        print('GPU name:', torch.cuda.get_device_name(0))\n",
    "    except Exception as e:\n",
    "        print('No se pudo obtener información de GPU:', e)\n",
    "    # Aumentar rendimiento en entradas de tamaño fijo\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    # Limitar hilos OpenMP si se desea (opcional)\n",
    "    os.environ['OMP_NUM_THREADS'] = os.environ.get('OMP_NUM_THREADS','4')\n",
    "    # Prueba rápida de asignación en GPU\n",
    "    try:\n",
    "        x = torch.randn(1024,1024, device=device)\n",
    "        print('GPU memoria asignada (bytes):', torch.cuda.memory_allocated())\n",
    "        del x\n",
    "    except Exception as e:\n",
    "        print('Prueba de GPU falló:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc9c71-0c0b-43ca-975c-135b3c0b3dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7f455b-6061-42d0-86fc-df5664dea725",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[1;32m     28\u001b[0m dataset \u001b[38;5;241m=\u001b[39m ImageDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjetos_salon/processed\u001b[39m\u001b[38;5;124m\"\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m224\u001b[39m)\u001b[38;5;66;03m#ajustar tamaño despues\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 388\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m RandomSampler(dataset, generator\u001b[38;5;241m=\u001b[39mgenerator)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/sampler.py:162\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, carpeta, size=224):\n",
    "        self.paths = sorted(glob.glob(os.path.join(carpeta, \"*.png\")))\n",
    "        self.size = size\n",
    "\n",
    "    def letterbox(self, img):\n",
    "        h, w = img.shape[:2]\n",
    "        s = self.size / max(h, w)\n",
    "        nh, nw = int(h * s), int(w * s)\n",
    "        img_resized = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "        pad_top = (self.size - nh) // 2\n",
    "        pad_left = (self.size - nw) // 2\n",
    "        out = np.full((self.size, self.size, 3), 114, dtype=np.uint8)\n",
    "        out[pad_top:pad_top + nh, pad_left:pad_left + nw] = img_resized\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.paths[idx], cv2.IMREAD_COLOR)\n",
    "        img = self.letterbox(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = torch.tensor(img).permute(2, 0, 1)  # C,H,W\n",
    "        return img\n",
    "\n",
    "dataset = ImageDataset(\"objetos_salon/processed/cpu\", size=224)#ajustar tamaño despues\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad2103-1f05-430b-b12d-96f6d16a5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78d4a6-8551-4280-bf18-0a9887deebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for imgs in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, imgs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "    print(f\"Época {epoch+1}, pérdida promedio: {total_loss/len(dataset):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d43c2dd-4aba-4d7a-a8e6-e82886e281fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "imgs = next(iter(loader))\n",
    "imgs = imgs[:5].to(device)\n",
    "recon = model(imgs).detach().cpu()\n",
    "\n",
    "for i in range(5):\n",
    "    orig = imgs[i].cpu().permute(1,2,0).numpy()\n",
    "    rec  = recon[i].permute(1,2,0).numpy()\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[0].imshow(orig); ax[0].set_title(\"Original\")\n",
    "    ax[1].imshow(rec); ax[1].set_title(\"Reconstruida\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5bd93-9a62-4cf9-ae92-2920b7c52bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#espacio latente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62484b7e-2e0e-4487-82c0-1eef662f54ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supone que model = Autoencoder() ya está entrenado\n",
    "model.eval()\n",
    "\n",
    "# Toma un lote de imágenes\n",
    "imgs = next(iter(loader))\n",
    "imgs = imgs.to(device)\n",
    "\n",
    "# Paso solo por el encoder\n",
    "with torch.no_grad():\n",
    "    z = model.encoder(imgs)\n",
    "\n",
    "print(\"Forma de z:\", z.shape)\n",
    "#32 imágenes (batch).\n",
    "#128 mapas de activación de tamaño 16×16 cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd5258-253d-4cd4-a015-2c64b011dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_flat = z.view(z.size(0), -1).cpu().numpy()\n",
    "print(\"Forma vectorizada:\", z_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901220d8-cdfc-4558-8d7b-98c19069d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducción de dimensionalidad\n",
    "z_pca = PCA(n_components=2).fit_transform(z_flat)\n",
    "# o: z_tsne = TSNE(n_components=2, perplexity=30).fit_transform(z_flat)\n",
    "\n",
    "plt.scatter(z_pca[:,0], z_pca[:,1], s=30, alpha=0.7)\n",
    "plt.title(\"Representación 2D del espacio latente (PCA)\")\n",
    "plt.xlabel(\"Comp. 1\")\n",
    "plt.ylabel(\"Comp. 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be96a54-ad00-49b7-b262-43cba31193ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos una imagen y su z\n",
    "x = imgs[0:1]\n",
    "with torch.no_grad():\n",
    "    z = model.encoder(x)\n",
    "\n",
    "# Pequeña perturbación del vector latente\n",
    "delta = torch.randn_like(z) * 0.1\n",
    "x_mod = model.decoder(z + delta)\n",
    "\n",
    "# Mostrar original, reconstruida y perturbada\n",
    "def show_pair(a, b, title_a, title_b):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(5,3))\n",
    "    ax[0].imshow(a); ax[0].set_title(title_a)\n",
    "    ax[1].imshow(b); ax[1].set_title(title_b)\n",
    "    plt.show()\n",
    "\n",
    "a = x[0].detach().cpu().permute(1,2,0).numpy()\n",
    "b = x_mod[0].detach().cpu().permute(1,2,0).numpy()\n",
    "show_pair(a, b, \"Original\", \"Reconstruida + perturbación\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7253426f-7dd9-43bc-86ab-ca55db196bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# super clasificador "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e43d21b-3f91-464d-b824-50a1c5426003",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledImageDataset(Dataset):\n",
    "    def __init__(self, root, size=224):\n",
    "        self.size = size\n",
    "        self.samples = []\n",
    "        self.classes = sorted([d for d in os.listdir(root) if os.path.isdir(os.path.join(root,d))])\n",
    "        self.class_to_idx = {c:i for i,c in enumerate(self.classes)}\n",
    "        for c in self.classes:\n",
    "            for p in glob.glob(os.path.join(root, c, \"*.png\")):\n",
    "                self.samples.append((p, self.class_to_idx[c]))\n",
    "\n",
    "    def letterbox(self, img):\n",
    "        h, w = img.shape[:2]\n",
    "        s = self.size / max(h, w)\n",
    "        nh, nw = int(h*s), int(w*s)\n",
    "        r = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "        out = np.full((self.size, self.size, 3), 114, dtype=np.uint8)\n",
    "        y0 = (self.size - nh)//2; x0 = (self.size - nw)//2\n",
    "        out[y0:y0+nh, x0:x0+nw] = r\n",
    "        return out\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        p, y = self.samples[i]\n",
    "        img = cv2.imread(p, cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(self.letterbox(img), cv2.COLOR_BGR2RGB)\n",
    "        x = torch.tensor(img, dtype=torch.float32).permute(2,0,1)/255.0\n",
    "        return x, torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed7be08-e95a-49a0-ba0c-c1e362db93c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = LabeledImageDataset(\"objetos_salon/processed\", size=224)\n",
    "n_classes = len(ds.classes)\n",
    "loader = DataLoader(ds, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "encoder = model.encoder.eval()            # usa tu autoencoder entrenado\n",
    "for p in encoder.parameters(): p.requires_grad = False\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ee0365-63be-409c-8b80-bc4c1752c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4936ca3e-af5c-4687-81cc-f85ec3603305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer features (flatten de z)\n",
    "X, Y = [], []\n",
    "with torch.no_grad():\n",
    "    for x, y in loader:\n",
    "        z = encoder(x.to(device))                 # [B, C, H, W]\n",
    "        z = torch.nn.functional.adaptive_avg_pool2d(z, 1)  # GAP -> [B,C,1,1]\n",
    "        z = z.view(z.size(0), -1).cpu().numpy()   # [B, C]\n",
    "        X.append(z); Y.append(y.numpy())\n",
    "X = np.concatenate(X, axis=0); Y = np.concatenate(Y, axis=0)\n",
    "\n",
    "Xtr, Xte, Ytr, Yte = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=42)\n",
    "clf = LogisticRegression(max_iter=2000).fit(Xtr, Ytr)\n",
    "pred = clf.predict(Xte)\n",
    "print(\"Acc:\", accuracy_score(Yte, pred))\n",
    "print(classification_report(Yte, pred, target_names=ds.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19ee10f-0a41-41dc-babb-bac0af07b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42360fd0-15f4-4fde-a259-ab4185cdf8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "head = nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(1),             # -> [B,C,1,1]\n",
    "    nn.Flatten(),                        # -> [B,C]\n",
    "    nn.Linear(128, n_classes)            # ajusta \"128\" a canales de tu encoder\n",
    ").to(device)\n",
    "\n",
    "crit = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(head.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(20):\n",
    "    head.train(); tot=0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            z = encoder(x)\n",
    "        logits = head(z)\n",
    "        loss = crit(logits, y)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        tot += loss.item()*x.size(0)\n",
    "    print(f\"epoch {epoch+1} loss {tot/len(ds):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4603546b-5d24-4a6d-b36f-73aff63a0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modo C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efca949d-2163-490c-a96f-786f5da47e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, p in encoder.named_parameters():\n",
    "    p.requires_grad = name.startswith(\"2.\")  # ejemplo: sólo último bloque\n",
    "opt = optim.Adam(list(filter(lambda t: t.requires_grad, encoder.parameters())) + list(head.parameters()), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3095f-b3a9-44bc-bcb9-b9d15d198e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    head.train(); tot=0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            z = encoder(x)\n",
    "        logits = head(z)\n",
    "        loss = crit(logits, y)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        tot += loss.item()*x.size(0)\n",
    "    print(f\"epoch {epoch+1} loss {tot/len(ds):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52584f0e-0326-411e-a63a-5e65a0f60c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimento con diferentes tamaños de cuello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1c1119-8dfb-4333-a945-5070eebe99fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderK(nn.Module):\n",
    "    def __init__(self, k=128):\n",
    "        super().__init__()\n",
    "        self.enc_base = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,2,1), nn.ReLU(),\n",
    "            nn.Conv2d(32,64,3,2,1), nn.ReLU(),\n",
    "            nn.Conv2d(64,128,3,2,1), nn.ReLU(),\n",
    "        )\n",
    "        self.enc_neck = nn.Sequential(\n",
    "            nn.Conv2d(128, k, 1, bias=False),\n",
    "            nn.BatchNorm2d(k),\n",
    "            nn.ReLU(inplace=True)           # activa y re-introduce sparsity útil\n",
    "        )\n",
    "        self.dec_neck = nn.Conv2d(k,128,1)  # sin activación aquí\n",
    "        self.dec_base = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128,64,4,2,1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64,32,4,2,1),  nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32,3,4,2,1),   nn.Sigmoid()\n",
    "        )\n",
    "    def encode(self,x):  return self.enc_neck(self.enc_base(x))\n",
    "    def decode(self,z):  return self.dec_base(self.dec_neck(z))\n",
    "    def forward(self,x): z=self.encode(x); return self.decode(z), z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cd74a-a5aa-42e6-b369-6b85b9e51c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ae(model, loader, device, epochs=10, lr=1e-3):\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for ep in range(epochs):\n",
    "        model.train(); tot = 0\n",
    "        for batch in loader:\n",
    "            x = batch if isinstance(batch, torch.Tensor) else batch[0]\n",
    "            x = x.to(device)\n",
    "            opt.zero_grad()\n",
    "            xhat, _ = model(x)\n",
    "            loss = F.mse_loss(xhat, x)\n",
    "            loss.backward(); opt.step()\n",
    "            tot += loss.item() * x.size(0)\n",
    "        print(f\"época {ep+1:02d}  MSE {tot/len(loader.dataset):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903198d2-2084-4988-bfa6-7517c3c9cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_recon(model, loader, device, batches=5):\n",
    "    model.eval(); mse_sum=0; n=0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(loader):\n",
    "            x = batch if isinstance(batch, torch.Tensor) else batch[0]\n",
    "            x = x.to(device)\n",
    "            xhat, _ = model(x)\n",
    "            mse = F.mse_loss(xhat, x).item()\n",
    "            mse_sum += mse; n += 1\n",
    "            if i+1 >= batches: break\n",
    "    mse = mse_sum/n\n",
    "    psnr = 10*math.log10(1.0/mse)\n",
    "    return mse, psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c7eb7-0894-40b6-b7cb-998a92af5946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_probe(model, loader, device, class_names):\n",
    "    X, Y = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            _, z = model(x)                                  # [B,k,16,16]\n",
    "            z = F.adaptive_avg_pool2d(z, 1).view(z.size(0), -1).cpu().numpy()\n",
    "            X.append(z); Y.append(y.numpy())\n",
    "    X = np.concatenate(X); Y = np.concatenate(Y)\n",
    "    Xtr, Xte, Ytr, Yte = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=42)\n",
    "    clf = LogisticRegression(max_iter=2000).fit(Xtr, Ytr)\n",
    "    acc = accuracy_score(Yte, clf.predict(Xte))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3c1a1-7880-48cf-bb58-ead77a92aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "k = 128\n",
    "model = AutoencoderK(k=k)\n",
    "\n",
    "# Entrenamiento (10 épocas sugeridas)\n",
    "train_ae(model, loader, device, epochs=10, lr=1e-3)\n",
    "\n",
    "# Reconstrucción: MSE y PSNR\n",
    "mse, psnr = eval_recon(model, loader, device, batches=8)\n",
    "print(f\"MSE recon: {mse:.6f}   PSNR: {psnr:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f0b990-0f52-422c-9256-f2e5bfde485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = linear_probe(model, loader, device, class_names=getattr(ds, \"classes\", None))\n",
    "print(f\"Linear probe (k=128) accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6820bc0d-21f3-4956-b6cb-b2a6b16fa368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5275b1b-e5eb-4200-8a0a-bc770bf91bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def inspect_latent(model, loader, device, batches=3):\n",
    "    model.eval()\n",
    "    shapes, means, stds, zeros = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for i,(x,*_) in enumerate(loader):\n",
    "            x = x.to(device) if isinstance(x, torch.Tensor) else x[0].to(device)\n",
    "            _, z = model(x)                      # [B,k,28,28] para input 224\n",
    "            shapes.append(z.shape)\n",
    "            zc = z.view(z.size(0), -1)\n",
    "            means.append(zc.mean(dim=1).cpu().numpy())\n",
    "            stds.append(zc.std(dim=1).cpu().numpy())\n",
    "            zeros.append((zc==0).float().mean(dim=1).cpu().numpy())  # ReLU sparsity\n",
    "            if i+1>=batches: break\n",
    "    print(\"shape ejemplos:\", shapes[:2])\n",
    "    print(\"mean z  (promedio):\", float(np.concatenate(means).mean()))\n",
    "    print(\"std z   (promedio):\", float(np.concatenate(stds).mean()))\n",
    "    print(\"sparsity (fracción de ceros):\", float(np.concatenate(zeros).mean()))\n",
    "\n",
    "# uso:\n",
    "inspect_latent(model, loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad5487-fd91-4a6a-aa22-c2c94006daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_size(k, h_in=224, downs=3):\n",
    "    h = h_in // (2**downs)\n",
    "    return k*h*h, h\n",
    "\n",
    "# ejemplo:\n",
    "n_params, h = latent_size(k=64)  # devuelve 64*28*28, 28\n",
    "print(\"n elem en z:\", n_params, \"mapa:\", f\"{64}x{h}x{h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6614f1-0e80-42f8-991e-cf3615d4c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para k= 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c00ba2-5dc9-41e8-8063-f39febb4bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_latent(model, loader, device, batches=3):\n",
    "    model.eval()\n",
    "    shapes, means, stds, zeros = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(loader):\n",
    "            x = batch if isinstance(batch, torch.Tensor) else batch[0]\n",
    "            x = x.to(device)\n",
    "            _, z = model(x)                          # [B,k,28,28] si input=224\n",
    "            shapes.append(tuple(z.shape))\n",
    "            zc = z.view(z.size(0), -1)\n",
    "            means.append(zc.mean(dim=1).cpu().numpy())                 # por muestra\n",
    "            stds.append(zc.std(dim=1).cpu().numpy())\n",
    "            zeros.append((zc==0).float().mean(dim=1).cpu().numpy())    # sparsity\n",
    "            if i+1 >= batches: break\n",
    "\n",
    "    means = np.concatenate(means); stds = np.concatenate(stds); zeros = np.concatenate(zeros)\n",
    "    print(\"shapes (ejemplos):\", shapes[:2])\n",
    "    print(f\"mean(z) promedio: {means.mean():.6f}\")\n",
    "    print(f\"std(z)  promedio: {stds.mean():.6f}\")\n",
    "    print(f\"sparsity promedio (fracción de ceros): {zeros.mean():.6f}\")\n",
    "\n",
    "# Uso:\n",
    "# inspect_latent(model, loader_ae, device)\n",
    "inspect_latent(model, loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc7ae7-c751-42fa-be47-a6a4e453302b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67304e-554f-4416-a493-2d9fc4b640e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
